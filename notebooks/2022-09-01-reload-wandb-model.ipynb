{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reload model from wandb cloud and use it to predict on arbitrary data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Make sure we're in the right directory\n",
    "if os.path.basename(os.getcwd()) in [\"notebooks\", \"examples\"]:\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data requirements:\n",
    "Please have the following files in the folder to which DATA_DIR points to (besides the inputs/outputs files):\n",
    "- ymonmean.1980_2010.compress.isosph5.CMIP6.historical.ensmean.Output.PrecipCon.nc'\n",
    "- ymonstd.1980_2010.compress.isosph5.CMIP6.historical.ensmean.Output.PrecipCon.nc'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "DATA_DIR = \"C:/Users/salva/PycharmProjects/Data/aibedo\"  # the data used for prediction must be here, as well as the cmip6 mean/std statistics\n",
    "# Input data filename (isosph is an order 6 icosahedron, isosph5 of order 5, etc.)\n",
    "filename_input = \"isosph5.denorm_nonorm.CESM2.historical.r1i1p1f1.Input.Exp8.nc\"\n",
    "# Output data filename is inferred from the input filename, do not edit!\n",
    "# E.g.: \"compress.isosph.CESM2.historical.r1i1p1f1.Output.nc\"\n",
    "filename_output = filename_input.replace(\"Input.Exp8.nc\", \"Output.nc\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from typing import *\n",
    "import wandb\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from aibedo.models import BaseModel\n",
    "from aibedo.utilities.wandb_api import reload_checkpoint_from_wandb, get_run_ids_for_hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First, reload the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the appropriate device (GPU or CPU) to use\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "overrides = [f'datamodule.data_dir={DATA_DIR}', f\"++model.use_auxiliary_vars=False\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use the following cell to get the wandb run ID corresponding to a (hyper-)parameter combination\n",
    "\n",
    "If there are multiple results, the search was not narrow enough (or it is the same run for different random seeds).\n",
    "In any case, you can look into more details of the run/model by browsing its wandb website (replacing $run_id with the run ID you want):\n",
    "*https://wandb.ai/salv47/AIBEDO/runs/$run_id*  (e.g. [this url](https://wandb.ai/salv47/AIBEDO/runs/25015z00) for run_id=\"25015z00\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['1rd92jmq']"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# options for datamodule/esm_for_training (the ESM(s) used to train the model) are:\n",
    "#   - 5 ESMs: [\"MRI-ESM2-0\", \"CESM2\", \"GFDL-ESM4\", \"MPI-ESM1-2-LR\", \"CESM2-WACCM\"]\n",
    "#   - 3 ESMs: [\"MRI-ESM2-0\", \"CESM2\", \"GFDL-ESM4\"]\n",
    "#   - 1 ESM: CESM2\n",
    "\n",
    "example_hyperparams = {\n",
    "    'datamodule/time_lag': 1,  # one of 0,1,2,3,4\n",
    "    'datamodule/esm_for_training':  [\"MRI-ESM2-0\", \"CESM2\", \"GFDL-ESM4\"],  #  or \"CESM2\" (as a string, *not* list)\n",
    "    'model/name': 'FNO',  # or FNO\n",
    "    'datamodule/output_vars': ['tas_nonorm', 'ps_nonorm', 'pr_nonorm'],  # or the same but with '_pre'\n",
    "    'datamodule/use_crel': True,  #  if False, crel is not used by the model (i.e. it is not an input)\n",
    "    'datamodule/use_crelSurf': True,  #  if False, crelSurf is not used by the model (i.e. it is not an input)\n",
    "    'datamodule/order': 5,   #  defines the order of the icosahedron: 5 or 6\n",
    "    'model/window': 1,  # keep this way\n",
    "}\n",
    "run_ids = get_run_ids_for_hyperparams(example_hyperparams)\n",
    "run_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Reload model(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "run_id_mlp_lag3_nonorm1 = \"1kxicry8\"\n",
    "reloaded_mlp = reload_checkpoint_from_wandb(run_id_mlp_lag3_nonorm1, override_key_value=overrides, try_local_recovery=False)['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre-process the data to be used for the ML model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "def concat_variables_into_channel_dim(data: xr.Dataset, variables: List[str]) -> np.ndarray:\n",
    "    \"\"\"Concatenate xarray variables into numpy channel dimension (last).\"\"\"\n",
    "    assert len(data[variables[0]].shape) == 2, \"Each input data variable must have two dimensions\"\n",
    "    data_ml = np.concatenate(\n",
    "        [np.expand_dims(data[var].values, axis=-1) for var in variables],\n",
    "        axis=-1  # last axis\n",
    "    )\n",
    "    return data_ml.astype(np.float32)\n",
    "\n",
    "def get_month_of_output_data(output_xarray: xr.Dataset) -> np.ndarray:\n",
    "    \"\"\" Get month of the snapshot (0-11)  \"\"\"\n",
    "    n_gridcells = len(output_xarray['ncells'])\n",
    "    # .item() is required here as only one timestep is used, the subtraction with -1 because we want 0-indexed months\n",
    "    month_of_snapshot = np.array(output_xarray['time.month'], dtype=np.float32) - 1\n",
    "    # now repeat the month for each grid cell/pixel\n",
    "    dataset_month = np.repeat(month_of_snapshot, n_gridcells)\n",
    "    return dataset_month.reshape([month_of_snapshot.shape[0], n_gridcells, 1])  # Add a dummy channel/feature dimension"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "def get_pytorch_model_data(input_xarray: xr.Dataset, output_xarray: xr.Dataset, input_vars: List[str]) -> torch.Tensor:\n",
    "    \"\"\"Get the tensor input data for the ML model.\"\"\"\n",
    "    # Concatenate all variables into the channel/feature dimension (last) of the input tensor\n",
    "    data_input = concat_variables_into_channel_dim(input_xarray, input_vars)\n",
    "    # Get the month of the snapshot (0-11), which is needed to denormalize the model predictions into their original scale\n",
    "    data_month = get_month_of_output_data(output_xarray)\n",
    "    # For convenience, we concatenate the month information to the input data, but it is *not* used by the model!\n",
    "    data_input = np.concatenate([data_input, data_month], axis=-1)\n",
    "    # Convert to torch tensor and move to CPU/GPU\n",
    "    data_input = torch.from_numpy(data_input).float().to(device)\n",
    "    return data_input"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "def predict_with_aibedo_model(aibedo_model: BaseModel, input_tensor: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Predict with the AiBEDO model.\n",
    "    Returns:\n",
    "        A dictionary of output-variable -> prediction-tensor key->value pairs for each variable {var}.\n",
    "        Keys with name {var} (e.g. 'pr') are in denormalized scale. Keys with name {var}_pre or {var}_nonorm are raw predictions of the ML model.\n",
    "        To only get the raw predictions, please use aibedo_model.raw_predict(input_tensor)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():  # No need to track the gradients during inference\n",
    "        prediction = aibedo_model.predict(input_tensor, return_normalized_outputs=True)  # if true, also return {var}_nonorm (or {var}_pre)\n",
    "    return prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prediction code\n",
    "#### Select below which model to use for prediction:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = reloaded_mlp      # Select which model to use for prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the actual data and process it"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ds_input = xr.open_dataset(f\"{DATA_DIR}/{filename_input}\")  # Input data\n",
    "ds_output = xr.open_dataset(f\"{DATA_DIR}/{filename_output}\") # Ground truth data\n",
    "input_ml = get_pytorch_model_data(ds_input, ds_output, input_vars=model.main_input_vars)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get AiBEDO predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions_ml = predict_with_aibedo_model(model, input_ml)\n",
    "predictions_ml.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "dsp_venv",
   "language": "python",
   "display_name": "DSP_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}