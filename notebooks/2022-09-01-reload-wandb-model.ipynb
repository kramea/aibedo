{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reload model from wandb cloud and use it to predict on arbitrary data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Make sure we're in the right directory\n",
    "if os.path.basename(os.getcwd()) in [\"notebooks\", \"examples\"]:\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data requirements:\n",
    "Please have the following files in the folder to which DATA_DIR points to (besides the inputs/outputs files):\n",
    "- ymonmean.1980_2010.compress.isosph5.CMIP6.historical.ensmean.Output.PrecipCon.nc'\n",
    "- ymonstd.1980_2010.compress.isosph5.CMIP6.historical.ensmean.Output.PrecipCon.nc'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "DATA_DIR = \"C:/Users/salva/PycharmProjects/Data/aibedo\"  # the data used for prediction must be here, as well as the cmip6 mean/std statistics\n",
    "# Input data filename (isosph is an order 6 icosahedron, isosph5 of order 5, etc.)\n",
    "filename_input = \"isosph5.denorm_nonorm.CESM2.historical.r1i1p1f1.Input.Exp8.nc\"\n",
    "# Output data filename is inferred from the input filename, do not edit!\n",
    "# E.g.: \"compress.isosph.CESM2.historical.r1i1p1f1.Output.nc\"\n",
    "filename_output = filename_input.replace(\"Input.Exp8.nc\", \"Output.nc\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from typing import *\n",
    "import wandb\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from aibedo.models import BaseModel\n",
    "from aibedo.utilities.wandb_api import reload_checkpoint_from_wandb, get_run_ids_for_hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First, reload the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the appropriate device (GPU or CPU) to use\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "overrides = [f'datamodule.data_dir={DATA_DIR}', f\"++model.use_auxiliary_vars=False\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use the following cell to get the wandb run ID corresponding to a (hyper-)parameter combination\n",
    "\n",
    "If there are multiple results, the search was not narrow enough (or it is the same run for different random seeds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['1kxicry8']"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# options for datamodule/esm_for_training (the ESM(s) used to train the model) are:\n",
    "#   - 5 ESMs: [\"MRI-ESM2-0\", \"CESM2\", \"GFDL-ESM4\", \"MPI-ESM1-2-LR\", \"CESM2-WACCM\"]\n",
    "#   - 3 ESMs: [\"MRI-ESM2-0\", \"CESM2\", \"GFDL-ESM4\"]\n",
    "#   - 1 ESM: CESM2\n",
    "\n",
    "example_hyperparams = {\n",
    "    'datamodule/time_lag': 3,  # one of 0,1,2,3,4\n",
    "    'datamodule/esm_for_training':  [\"MRI-ESM2-0\", \"CESM2\", \"GFDL-ESM4\"],  #  or \"CESM2\" (as a string, *not* list)\n",
    "    'model/name': 'MLP',  # or FNO\n",
    "    'datamodule/output_vars': ['tas_nonorm', 'ps_nonorm', 'pr_nonorm'],  # or the same but with '_pre'\n",
    "    'model/window': 1  # keep this way\n",
    "}\n",
    "run_ids = get_run_ids_for_hyperparams(example_hyperparams)\n",
    "run_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Reload model(s):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "run_id_mlp_lag3_nonorm1 = \"1kxicry8\"\n",
    "reloaded_mlp = reload_checkpoint_from_wandb(run_id_mlp_lag3_nonorm1, override_key_value=overrides, try_local_recovery=False)['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre-process the data to be used for the ML model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def concat_variables_into_channel_dim(data: xr.Dataset, variables: List[str]) -> np.ndarray:\n",
    "    \"\"\"Concatenate xarray variables into numpy channel dimension (last).\"\"\"\n",
    "    assert len(data[variables[0]].shape) == 2, \"Each input data variable must have two dimensions\"\n",
    "    data_ml = np.concatenate(\n",
    "        [np.expand_dims(data[var].values, axis=-1) for var in variables],\n",
    "        axis=-1  # last axis\n",
    "    )\n",
    "    return data_ml.astype(np.float32)\n",
    "\n",
    "def get_month_of_output_data(output_xarray: xr.Dataset) -> np.ndarray:\n",
    "    \"\"\" Get month of the snapshot (0-11)  \"\"\"\n",
    "    n_gridcells = len(output_xarray['ncells'])\n",
    "    # .item() is required here as only one timestep is used, the subtraction with -1 because we want 0-indexed months\n",
    "    month_of_snapshot = np.array(output_xarray.coords['time'].item().month, dtype=np.float32) - 1\n",
    "    # now repeat the month for each grid cell/pixel\n",
    "    dataset_month = np.repeat(month_of_snapshot, n_gridcells)\n",
    "    return dataset_month.reshape([1, n_gridcells, 1])  # Add a batch dimension and dummy channel/feature dimension"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_pytorch_model_data(input_xarray: xr.Dataset, output_xarray: xr.Dataset, input_vars: List[str]) -> torch.Tensor:\n",
    "    \"\"\"Get the tensor input data for the ML model.\"\"\"\n",
    "    # Concatenate all variables into the channel/feature dimension (last) of the input tensor\n",
    "    data_input = concat_variables_into_channel_dim(input_xarray, input_vars)\n",
    "    # Get the month of the snapshot (0-11), which is needed to denormalize the model predictions into their original scale\n",
    "    data_month = get_month_of_output_data(output_xarray)\n",
    "    # For convenience, we concatenate the month information to the input data, but it is *not* used by the model!\n",
    "    data_input = np.concatenate([data_input, data_month], axis=-1)\n",
    "    # Convert to torch tensor and move to CPU/GPU\n",
    "    data_input = torch.from_numpy(data_input).float().to(device)\n",
    "    return data_input"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict_with_aibedo_model(aibedo_model: BaseModel, input_tensor: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Predict with the AiBEDO model.\n",
    "    Returns:\n",
    "        A dictionary of output-variable -> prediction-tensor key->value pairs for each variable {var}.\n",
    "        Keys with name {var} (e.g. 'pr') are in denormalized scale. Keys with name {var}_pre or {var}_nonorm are raw predictions of the ML model.\n",
    "        To only get the raw predictions, please use aibedo_model.raw_predict(input_tensor)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():  # No need to track the gradients during inference\n",
    "        prediction = aibedo_model.predict(input_tensor, return_normalized_outputs=True)  # if true, also return {var}_nonorm (or {var}_pre)\n",
    "    return prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prediction code\n",
    "#### Select below which model to use for prediction:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = reloaded_mlp      # Select which model to use for prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the actual data and process it"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ds_input = xr.open_dataset(f\"{DATA_DIR}/{filename_input}\")  # Input data\n",
    "ds_output = xr.open_dataset(f\"{DATA_DIR}/{filename_output}\") # Ground truth data\n",
    "input_ml = get_pytorch_model_data(ds_input, ds_output, input_vars=model.main_input_vars)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get AiBEDO predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions_ml = predict_with_aibedo_model(model, input_ml)\n",
    "predictions_ml.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "dsp_venv",
   "language": "python",
   "display_name": "DSP_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}