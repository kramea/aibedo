{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Make sure we're in the right directory\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    os.chdir(\"..\")\n",
    "import torch\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from typing import *\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "from aibedo.models.MLP import AIBEDO_MLP\n",
    "from aibedo.models.base_model import BaseModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Paths and filenames\n",
    "## ***Please edit here to your own paths and desired filenames***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define the path where the data and model checkpoint is stored\n",
    "DATA_DIR = \"../../data\"\n",
    "# Input data filename (isosph is an order 6 icosahedron, isosph5 of order 5, etc.)\n",
    "filename_input = \"compress.isosph.CESM2.historical.r1i1p1f1.Input.Exp8_fixed.nc\"\n",
    "# Output data filename (inferred from the input filename), do not edit!\n",
    "# E.g.: \"compress.isosph.CESM2.historical.r1i1p1f1.Output.PrecipCon.nc\"\n",
    "filename_output = filename_input.replace(\"Input.Exp8_fixed\", \"Output.PrecipCon\")\n",
    "# Define the timestep to use as input data (as absolute index, -10 means 10 timesteps before the last timestep)\n",
    "prediction_timestep = -10\n",
    "# Define the ML model checkpoint path to be reloaded\n",
    "CKPT = 'epoch023_seed15.ckpt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Some constants that we will use later on *(do not edit)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# _pre means that the variable has been pre-processed (i.e. deseasonalized, detrended, etc.)\n",
    "VARS_INPUT = [ 'crelSurf_pre', 'crel_pre', 'cresSurf_pre', 'cres_pre', 'netTOAcs_pre', 'lsMask', 'netSurfcs_pre']\n",
    "VARS_OUTPUT = ['tas', 'ps', 'pr']\n",
    "output_var_clean_name = {\n",
    "    'tas': 'Air Temperature',\n",
    "    'ps': \"Surface Pressure\",\n",
    "    'pr': \"Precipitation\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# (Re-)Loading\n",
    "### Load the pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ds_input = xr.open_dataset(f\"{DATA_DIR}/{filename_input}\")  # Input data\n",
    "ds_output = xr.open_dataset(f\"{DATA_DIR}/{filename_output}\") # Ground truth data\n",
    "ds_input.crel_pre.values.shape  # (time, pixel-in-icosahedron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the appropriate device (GPU or CPU) to use\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Load the trained model checkpoint (its weights, hyperparameters, etc.)\n",
    "saved_model = torch.load(f\"{DATA_DIR}/{CKPT}\", map_location=device)\n",
    "saved_model['hyper_parameters']['datamodule_config']['data_dir'] = DATA_DIR   # Update the data directory\n",
    "# Get the appropriate architecture to use based on the hyperparameters\n",
    "model = AIBEDO_MLP(**saved_model['hyper_parameters'], use_auxiliary_vars=False)\n",
    "saved_model['hyper_parameters']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Reload the checkpoint (model weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(saved_model['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Reload the checkpoint (model weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(saved_model['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pre-process the data to be used for the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(saved_model['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pre-process the data to be used for the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def concat_variables_into_channel_dim(data: xr.Dataset, variables: List[str]) -> np.ndarray:\n",
    "    \"\"\"Concatenate xarray variables into numpy channel dimension (last).\"\"\"\n",
    "    assert len(data[variables[0]].shape) == 1, \"Each input data variable must have only one dimension\"\n",
    "    data_ml = np.concatenate(\n",
    "        [data[var].values.reshape((-1, 1)) for var in variables],\n",
    "        axis=-1  # last axis\n",
    "    )\n",
    "    return np.expand_dims(data_ml, axis=0).astype(np.float32)  # Add a batch dimension\n",
    "\n",
    "def get_month_of_output_data(output_xarray: xr.Dataset) -> np.ndarray:\n",
    "    \"\"\" Get month of the snapshot (0-11)  \"\"\"\n",
    "    n_gridcells = len(output_xarray['ncells'])\n",
    "    # .item() is required here as only one timestep is used, the subtraction with -1 because we want 0-indexed months\n",
    "    month_of_snapshot = np.array(output_xarray.coords['time'].item().month, dtype=np.float32) - 1\n",
    "    # now repeat the month for each grid cell/pixel\n",
    "    dataset_month = np.repeat(month_of_snapshot, n_gridcells)\n",
    "    return dataset_month.reshape([1, n_gridcells, 1])  # Add a batch dimension and dummy channel/feature dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_pytorch_model_data(input_xarray: xr.Dataset, output_xarray: xr.Dataset, timestep_i: int) -> torch.Tensor:\n",
    "    \"\"\"Get the tensor input data for the ML model at the specified timestep.\"\"\"\n",
    "    snapshot_input_raw = input_xarray.isel(time=timestep_i)\n",
    "    snapshot_output_raw = output_xarray.isel(time=timestep_i)\n",
    "    # Concatenate all variables into the channel/feature dimension (last) of the input tensor\n",
    "    data_input = concat_variables_into_channel_dim(snapshot_input_raw, VARS_INPUT)\n",
    "    # Get the month of the snapshot (0-11), which is needed to denormalize the model predictions into their original scale\n",
    "    data_month = get_month_of_output_data(snapshot_output_raw)\n",
    "    # For convenience, we concatenate the month information to the input data, but it is *not* used by the model!\n",
    "    data_input = np.concatenate([data_input, data_month], axis=-1)\n",
    "    # Convert to torch tensor and move to CPU/GPU\n",
    "    data_input = torch.from_numpy(data_input).float().to(device)\n",
    "    return data_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "snapshot_input_ml = get_pytorch_model_data(ds_input, ds_output, prediction_timestep)\n",
    "snapshot_target = ds_output.isel(time=prediction_timestep)\n",
    "snapshot_input_ml.shape  # (batch-dimension, icosahedron-grid-dimension, feature-dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Prediction with the AiBEDO model\n",
    "###### ***Note:*** Please always use the ```model.predict(input_tensor)``` method instead of ```model(input_tensor)```!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict_with_aibedo_model(aibedo_model: BaseModel, input_tensor: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Predict with the AiBEDO model.\n",
    "    Returns:\n",
    "        A dictionary of output-variable -> prediction-tensor key->value pairs.\n",
    "        Each prediction-tensor has been denormalized to original scale (e.g. temperature in kelvin)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():  # No need to track the gradients during inference\n",
    "        prediction = aibedo_model.predict(input_tensor)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "snapshot_prediction = predict_with_aibedo_model(model, snapshot_input_ml)\n",
    "snapshot_prediction.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Post-processing and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_predictions_xarray(targets_ds: xr.Dataset, predictions_ds: xr.Dataset) -> xr.Dataset:\n",
    "    \"\"\" Add the torch tensor predictions to the xarray targets dataset as well as errors (bias, MAE). \"\"\"\n",
    "    return_ds = targets_ds.copy()\n",
    "    for var, pred in predictions_ds.items():\n",
    "        pred_key = f\"{var}_pred\"\n",
    "        return_ds[pred_key] = ('ncells', pred.squeeze().cpu().numpy())\n",
    "        # compute the error\n",
    "        diff_err = return_ds[pred_key] - return_ds[var]\n",
    "        return_ds[f'{var}_mae'] = np.abs(diff_err)\n",
    "        return_ds[f'{var}_bias'] = diff_err\n",
    "    return return_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "snapshot_postprocessed = get_predictions_xarray(snapshot_target, snapshot_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### A plotting script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def single_snapshot_plotting(postprocessed_xarray: xr.Dataset,\n",
    "                       **kwargs\n",
    "                       ):\n",
    "    proj = ccrs.PlateCarree()\n",
    "    plot_kwargs = dict(\n",
    "        ds=postprocessed_xarray,\n",
    "        x='lon',\n",
    "        y='lat',\n",
    "        transform=proj, subplot_kws={'projection': proj},\n",
    "        cbar_kwargs={'shrink': 0.8,  # make cbar smaller/larger\n",
    "                     'pad': 0.01,  # padding between right-most subplot and cbar\n",
    "                     'fraction': 0.05}, **kwargs\n",
    "    )\n",
    "    nrows, ncols = 4, 3\n",
    "    fig, axs = plt.subplots(nrows, ncols, sharex=True, sharey=True,\n",
    "                            subplot_kw={'projection': proj},\n",
    "                            gridspec_kw={'wspace': 0.07, 'hspace': 0,\n",
    "                                         'top': 1., 'bottom': 0., 'left': 0., 'right': 1.},\n",
    "                            figsize=(ncols * 12, nrows * 6)  # <- adjust figsize but keep ratio ncols/nrows\n",
    "                            )\n",
    "\n",
    "    for j, var in enumerate(VARS_OUTPUT):\n",
    "        p_target = xr.plot.scatter(hue=var, ax=axs[0, j], **plot_kwargs)\n",
    "        p_preds = xr.plot.scatter(hue=f'{var}_pred', ax=axs[1, j], vmin=p_target.colorbar.vmin, vmax=p_target.colorbar.vmax, **plot_kwargs)\n",
    "        p_bias = xr.plot.scatter(hue=f'{var}_bias', ax=axs[2, j], **plot_kwargs)\n",
    "        p_mae = xr.plot.scatter(hue=f'{var}_mae', ax=axs[3, j], **plot_kwargs)\n",
    "\n",
    "        # Set title\n",
    "        axs[0, j].set_title(output_var_clean_name[var], size=30)\n",
    "\n",
    "        # Edit colorbar\n",
    "        for p, label in zip([p_target, p_preds, p_bias, p_mae], ['Targets', \"AiBEDO\", 'Bias', \"MAE\"]):\n",
    "            p.colorbar.set_label(label, size=25)\n",
    "            p.colorbar.ax.tick_params(labelsize=18)\n",
    "\n",
    "    for ax in list(axs.flat):\n",
    "        ax.coastlines(linewidth=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plotting the results\n",
    "**Legend:**\n",
    "\n",
    "    Each column is a different (denormalized) output variable.\n",
    "    \n",
    "    Rows:\n",
    "    - First row: Targets\n",
    "    - Second row: AiBEDO model predictions\n",
    "    - Third row: Bias error (AiBEDO - Targets)\n",
    "    - Fourth row: MAE error (|AiBEDO - Targets|)\n",
    "   \n",
    "    Note the 1e-5 in the precipitation errors!\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "single_snapshot_plotting(snapshot_postprocessed, robust=True, s=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}