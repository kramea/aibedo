{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Union\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#import xarray\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "LOGGER = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load rainfall data prepared for MTS-LSTM paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "key_list = ['in_highres', 'out_highres', 'in_lowres', 'out_lowres']\n",
    "\n",
    "HR_SEQLEN = 336\n",
    "LR_SEQLEN = 365\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rainfall_data(in_HR_fname, in_LR_fname, out_HR_fname, out_LR_fname):\n",
    "    x_d_1H_array = torch.tensor(np.load(in_HR_fname))\n",
    "    x_d_1D_array = torch.tensor(np.load(in_LR_fname))\n",
    "    y_1H_array = torch.tensor(np.load(out_HR_fname))\n",
    "    y_1D_array = torch.tensor(np.load(out_LR_fname))\n",
    "    \n",
    "    print(\"in_HR: \", x_d_1H_array.shape, x_d_1H_array.dtype)\n",
    "    print(\"in_LR: \",x_d_1D_array.shape, x_d_1D_array.dtype)\n",
    "    print(\"out_HR: \", y_1H_array.shape, y_1H_array.dtype)\n",
    "    print(\"out_LR: \",y_1D_array.shape, y_1D_array.dtype)\n",
    "    \n",
    "    data_dict = dict(zip(key_list,[x_d_1H_array, y_1H_array, x_d_1D_array,  y_1D_array]))\n",
    "    \n",
    "    return data_dict\n",
    "    \n",
    "    \n",
    "    \n",
    "def load_lookuptable(HR_lookup_fname, LR_lookup_fname):\n",
    "    \"\"\"Metadata specifically for rainfall data\"\"\"\n",
    "    H_lookup = np.load(HR_lookup_fname)\n",
    "    D_lookup = np.load(LR_lookup_fname)\n",
    "    \n",
    "    return H_lookup, D_lookup\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_HR:  torch.Size([87648, 16]) torch.float32\n",
      "in_LR:  torch.Size([3652, 5]) torch.float32\n",
      "out_HR:  torch.Size([87648, 1]) torch.float32\n",
      "out_LR:  torch.Size([3652, 1]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "#training data\n",
    "\n",
    "train_datadict = load_rainfall_data(\"x_d_1H_array.npy\", \"x_d_1D_array.npy\", \"y_1H_array.npy\", \"y_1D_array.npy\")\n",
    "H_lookup_train, D_lookup_train = load_lookuptable(\"H_lookup.npy\", \"D_lookup.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_HR:  torch.Size([35016, 16]) torch.float32\n",
      "in_LR:  torch.Size([1459, 5]) torch.float32\n",
      "out_HR:  torch.Size([35016, 1]) torch.float32\n",
      "out_LR:  torch.Size([1459, 1]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "#validation data\n",
    "\n",
    "validation_datadict = load_rainfall_data(\"x_d_1H_array_val.npy\", \"x_d_1D_array_val.npy\", \"y_1H_array_val.npy\", \"y_1D_array_val.npy\")\n",
    "H_lookup_val, D_lookup_val = load_lookuptable(\"H_lookup_val.npy\", \"D_lookup_val.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_HR:  torch.Size([70104, 16]) torch.float32\n",
      "in_LR:  torch.Size([2921, 5]) torch.float32\n",
      "out_HR:  torch.Size([70104, 1]) torch.float32\n",
      "out_LR:  torch.Size([2921, 1]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "#test data\n",
    "\n",
    "test_datadict = load_rainfall_data(\"x_d_1H_array_test.npy\", \"x_d_1D_array_test.npy\", \"y_1H_array_test.npy\", \"y_1D_array_test.npy\")\n",
    "H_lookup_test, D_lookup_test = load_lookuptable(\"H_lookup_test.npy\", \"D_lookup_test.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalDS_rainfall(Dataset):\n",
    "    def __init__(self, data_dict, hr_seq_len, lr_seq_len, hlkup, dlkup):\n",
    "        self.datadict = data_dict\n",
    "        self.hr_seq_len = hr_seq_len\n",
    "        self.lr_seq_len = lr_seq_len\n",
    "        self.freq_factor = 24.0\n",
    "        self.hlookup = hlkup\n",
    "        self.dlookup = dlkup\n",
    "        self.num_samples = self.hlookup.shape[0] #hardcoded right now for this example DS\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index)-> Dict[str, torch.Tensor]:\n",
    "        hr_idx = self.hlookup[index]\n",
    "        lr_idx = self.dlookup[index]\n",
    "        \n",
    "        \n",
    "        sample = {}\n",
    "        \n",
    "        #populate for high res first (i.e. hourly)\n",
    "        sample[f'x_d_1H'] = self.datadict['in_highres'][hr_idx - self.hr_seq_len + 1: hr_idx+1]\n",
    "        sample[f'y_1H'] = self.datadict['out_highres'][hr_idx - self.hr_seq_len + 1: hr_idx+1]\n",
    "        \n",
    "        sample[f'x_d_1D'] = self.datadict['in_lowres'][lr_idx - self.lr_seq_len + 1: lr_idx+1]\n",
    "        sample[f'y_1D'] = self.datadict['out_lowres'][lr_idx - self.lr_seq_len + 1: lr_idx+1]\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = TemporalDS_rainfall(train_datadict, hr_seq_len=HR_SEQLEN, lr_seq_len=LR_SEQLEN, hlkup=H_lookup_train, dlkup=D_lookup_train)\n",
    "ds_val = TemporalDS_rainfall(validation_datadict, hr_seq_len=HR_SEQLEN, lr_seq_len=LR_SEQLEN, hlkup=H_lookup_val, dlkup=D_lookup_val)\n",
    "ds_test = TemporalDS_rainfall(test_datadict, hr_seq_len=HR_SEQLEN, lr_seq_len=LR_SEQLEN, hlkup=H_lookup_test, dlkup=D_lookup_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dl_val = DataLoader(ds_val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "dl_test = DataLoader(ds_test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lstm class and util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralhydrology.utils.config import Config\n",
    "from neuralhydrology.utils.samplingutils import sample_pointpredictions\n",
    "from neuralhydrology.datautils.utils import get_frequency_factor, sort_frequencies\n",
    "from neuralhydrology.modelzoo.head import get_head\n",
    "\n",
    "import neuralhydrology.training.loss as loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    \n",
    "    # specify submodules of the model that can later be used for finetuning. Names must match class attributes\n",
    "    module_parts = []\n",
    "\n",
    "    def __init__(self, cfg: Config):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        self.output_size = len(cfg.output_dim)\n",
    "        # if cfg.head.lower() == 'gmm':\n",
    "        #     self.output_size *= 3 * cfg.n_distributions\n",
    "        # elif cfg.head.lower() == 'cmal':\n",
    "        #     self.output_size *= 4 * cfg.n_distributions\n",
    "        # elif cfg.head.lower() == 'umal':\n",
    "        #     self.output_size *= 2\n",
    "\n",
    "    def sample(self, data: Dict[str, torch.Tensor], n_samples: int) -> Dict[str, torch.Tensor]:\n",
    "        \n",
    "        return sample_pointpredictions(self, data, n_samples)\n",
    "\n",
    "    def forward(self, data: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        \n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTSLSTM(BaseModel):\n",
    "    \n",
    "    # specify submodules of the model that can later be used for finetuning. Names must match class attributes\n",
    "    module_parts = ['lstms', 'transfer_fcs', 'heads']\n",
    "\n",
    "    def __init__(self, cfg: Config):\n",
    "        super(MTSLSTM, self).__init__(cfg=cfg)\n",
    "        self.lstms = None\n",
    "        self.transfer_fcs = None\n",
    "        self.heads = None\n",
    "        self.dropout = None\n",
    "\n",
    "        self._slice_timestep = {}\n",
    "        self._frequency_factors = []\n",
    "\n",
    "        self._seq_lengths = cfg.seq_length\n",
    "        self._is_shared_mtslstm = self.cfg.shared_mtslstm  # default: a distinct LSTM per timescale\n",
    "        self._transfer_mtslstm_states = self.cfg.transfer_mtslstm_states  # default: linear transfer layer\n",
    "        transfer_modes = [None, \"None\", \"identity\", \"linear\"]\n",
    "        if self._transfer_mtslstm_states[\"h\"] not in transfer_modes \\\n",
    "                or self._transfer_mtslstm_states[\"c\"] not in transfer_modes:\n",
    "            raise ValueError(f\"MTS-LSTM supports state transfer modes {transfer_modes}\")\n",
    "\n",
    "        if len(cfg.use_frequencies) < 2:\n",
    "            raise ValueError(\"MTS-LSTM expects more than one input frequency\")\n",
    "        self._frequencies = sort_frequencies(cfg.use_frequencies)\n",
    "\n",
    "        # start to count the number of inputs\n",
    "        input_sizes = len(cfg.static_attributes + cfg.hydroatlas_attributes + cfg.evolving_attributes)\n",
    "\n",
    "        # if is_shared_mtslstm, the LSTM gets an additional frequency flag as input.\n",
    "        if self._is_shared_mtslstm:\n",
    "            input_sizes += len(self._frequencies)\n",
    "\n",
    "        if cfg.use_basin_id_encoding:\n",
    "            input_sizes += cfg.number_of_basins\n",
    "        if cfg.head.lower() == \"umal\":\n",
    "            input_sizes += 1\n",
    "\n",
    "        if isinstance(cfg.dynamic_inputs, list):\n",
    "            input_sizes = {freq: input_sizes + len(cfg.dynamic_inputs) for freq in self._frequencies}\n",
    "        else:\n",
    "            if self._is_shared_mtslstm:\n",
    "                raise ValueError(f'Different inputs not allowed if shared_mtslstm is used.')\n",
    "            input_sizes = {freq: input_sizes + len(cfg.dynamic_inputs[freq]) for freq in self._frequencies}\n",
    "\n",
    "        if not isinstance(cfg.hidden_size, dict):\n",
    "            LOGGER.info(\"No specific hidden size for frequencies are specified. Same hidden size is used for all.\")\n",
    "            self._hidden_size = {freq: cfg.hidden_size for freq in self._frequencies}\n",
    "        else:\n",
    "            self._hidden_size = cfg.hidden_size\n",
    "\n",
    "        if (self._is_shared_mtslstm\n",
    "            or self._transfer_mtslstm_states[\"h\"] == \"identity\"\n",
    "            or self._transfer_mtslstm_states[\"c\"] == \"identity\") \\\n",
    "                and any(size != self._hidden_size[self._frequencies[0]] for size in self._hidden_size.values()):\n",
    "            raise ValueError(\"All hidden sizes must be equal if shared_mtslstm is used or state transfer=identity.\")\n",
    "\n",
    "        # create layer depending on selected frequencies\n",
    "        self._init_modules(input_sizes)\n",
    "        self._reset_parameters()\n",
    "\n",
    "        # frequency factors are needed to determine the time step of information transfer\n",
    "        self._init_frequency_factors_and_slice_timesteps()\n",
    "\n",
    "    def _init_modules(self, input_sizes: Dict[str, int]):\n",
    "        self.lstms = nn.ModuleDict()\n",
    "        self.transfer_fcs = nn.ModuleDict()\n",
    "        self.heads = nn.ModuleDict()\n",
    "        self.dropout = nn.Dropout(p=self.cfg.output_dropout)\n",
    "        for idx, freq in enumerate(self._frequencies):\n",
    "            freq_input_size = input_sizes[freq]\n",
    "\n",
    "            if self._is_shared_mtslstm and idx > 0:\n",
    "                self.lstms[freq] = self.lstms[self._frequencies[idx - 1]]  # same LSTM for all frequencies.\n",
    "                self.heads[freq] = self.heads[self._frequencies[idx - 1]]  # same head for all frequencies.\n",
    "            else:\n",
    "                self.lstms[freq] = nn.LSTM(input_size=freq_input_size, hidden_size=self._hidden_size[freq])\n",
    "                self.heads[freq] = get_head(self.cfg, n_in=self._hidden_size[freq], n_out=self.output_size)\n",
    "\n",
    "            if idx < len(self._frequencies) - 1:\n",
    "                for state in [\"c\", \"h\"]:\n",
    "                    if self._transfer_mtslstm_states[state] == \"linear\":\n",
    "                        self.transfer_fcs[f\"{state}_{freq}\"] = nn.Linear(self._hidden_size[freq],\n",
    "                                                                         self._hidden_size[self._frequencies[idx + 1]])\n",
    "                    elif self._transfer_mtslstm_states[state] == \"identity\":\n",
    "                        self.transfer_fcs[f\"{state}_{freq}\"] = nn.Identity()\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "    def _init_frequency_factors_and_slice_timesteps(self):\n",
    "        for idx, freq in enumerate(self._frequencies):\n",
    "            if idx < len(self._frequencies) - 1:\n",
    "                frequency_factor = get_frequency_factor(freq, self._frequencies[idx + 1])\n",
    "                if frequency_factor != int(frequency_factor):\n",
    "                    raise ValueError('Adjacent frequencies must be multiples of each other.')\n",
    "                self._frequency_factors.append(int(frequency_factor))\n",
    "                # we want to pass the state of the day _before_ the next higher frequency starts,\n",
    "                # because e.g. the mean of a day is stored at the same date at 00:00 in the morning.\n",
    "                slice_timestep = int(self._seq_lengths[self._frequencies[idx + 1]] / self._frequency_factors[idx])\n",
    "                self._slice_timestep[freq] = slice_timestep\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        if self.cfg.initial_forget_bias is not None:\n",
    "            for freq in self._frequencies:\n",
    "                hidden_size = self._hidden_size[freq]\n",
    "                self.lstms[freq].bias_hh_l0.data[hidden_size:2 * hidden_size] = self.cfg.initial_forget_bias\n",
    "\n",
    "    def _prepare_inputs(self, data: Dict[str, torch.Tensor], freq: str) -> torch.Tensor:\n",
    "        \"\"\"Concat all different inputs to the time series input\"\"\"\n",
    "        suffix = f\"_{freq}\"\n",
    "        # transpose to [seq_length, batch_size, n_features]\n",
    "        x_d = data[f'x_d{suffix}'].transpose(0, 1)\n",
    "\n",
    "        # concat all inputs\n",
    "        if f'x_s{suffix}' in data and 'x_one_hot' in data:\n",
    "            x_s = data[f'x_s{suffix}'].unsqueeze(0).repeat(x_d.shape[0], 1, 1)\n",
    "            x_one_hot = data['x_one_hot'].unsqueeze(0).repeat(x_d.shape[0], 1, 1)\n",
    "            x_d = torch.cat([x_d, x_s, x_one_hot], dim=-1)\n",
    "        elif f'x_s{suffix}' in data:\n",
    "            x_s = data[f'x_s{suffix}'].unsqueeze(0).repeat(x_d.shape[0], 1, 1)\n",
    "            x_d = torch.cat([x_d, x_s], dim=-1)\n",
    "        elif 'x_one_hot' in data:\n",
    "            x_one_hot = data['x_one_hot'].unsqueeze(0).repeat(x_d.shape[0], 1, 1)\n",
    "            x_d = torch.cat([x_d, x_one_hot], dim=-1)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if self._is_shared_mtslstm:\n",
    "            # add frequency one-hot encoding\n",
    "            idx = self._frequencies.index(freq)\n",
    "            one_hot_freq = torch.zeros(x_d.shape[0], x_d.shape[1], len(self._frequencies)).to(x_d)\n",
    "            one_hot_freq[:, :, idx] = 1\n",
    "            x_d = torch.cat([x_d, one_hot_freq], dim=2)\n",
    "\n",
    "        return x_d\n",
    "\n",
    "    def forward(self, data: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Perform a forward pass on the MTS-LSTM model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : Dict[str, torch.Tensor]\n",
    "            Input data for the forward pass. See the documentation overview of all models for details on the dict keys.\n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, torch.Tensor]\n",
    "            Model predictions for each target timescale.\n",
    "        \"\"\"\n",
    "        x_d = {freq: self._prepare_inputs(data, freq) for freq in self._frequencies}\n",
    "\n",
    "        # initial states for lowest frequencies are set to zeros\n",
    "        batch_size = x_d[self._frequencies[0]].shape[1]\n",
    "        lowest_freq_hidden_size = self._hidden_size[self._frequencies[0]]\n",
    "        h_0_transfer = x_d[self._frequencies[0]].new_zeros((1, batch_size, lowest_freq_hidden_size))\n",
    "        c_0_transfer = torch.zeros_like(h_0_transfer)\n",
    "\n",
    "        outputs = {}\n",
    "        for idx, freq in enumerate(self._frequencies):\n",
    "            if idx < len(self._frequencies) - 1:\n",
    "                # get predictions and state up to the time step of information transfer\n",
    "                slice_timestep = self._slice_timestep[freq]\n",
    "                lstm_output_slice1, (h_n_slice1, c_n_slice1) = self.lstms[freq](x_d[freq][:-slice_timestep],\n",
    "                                                                                (h_0_transfer, c_0_transfer))\n",
    "\n",
    "                # project the states through a hidden layer to the dimensions of the next LSTM\n",
    "                if self._transfer_mtslstm_states[\"h\"] is not None:\n",
    "                    h_0_transfer = self.transfer_fcs[f\"h_{freq}\"](h_n_slice1)\n",
    "                if self._transfer_mtslstm_states[\"c\"] is not None:\n",
    "                    c_0_transfer = self.transfer_fcs[f\"c_{freq}\"](c_n_slice1)\n",
    "\n",
    "                # get predictions of remaining part and concat results\n",
    "                lstm_output_slice2, _ = self.lstms[freq](x_d[freq][-slice_timestep:], (h_n_slice1, c_n_slice1))\n",
    "                lstm_output = torch.cat([lstm_output_slice1, lstm_output_slice2], dim=0)\n",
    "\n",
    "            else:\n",
    "                # for highest frequency, we can pass the entire sequence at once\n",
    "                lstm_output, _ = self.lstms[freq](x_d[freq], (h_0_transfer, c_0_transfer))\n",
    "\n",
    "            head_out = self.heads[freq](self.dropout(lstm_output.transpose(0, 1)))\n",
    "            outputs.update({f'{key}_{freq}': value for key, value in head_out.items()})\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_predictions_and_loss(model, data, l_obj):\n",
    "    predictions = model(data)\n",
    "    loss = l_obj(predictions, data)\n",
    "    return predictions, loss.item()\n",
    "\n",
    "def _subset_targets(data, predictions, predict_last_n, freq):\n",
    "    y_hat_sub = predictions[f'y_hat{freq}'][:, -predict_last_n:, :]\n",
    "    y_sub = data[f'y{freq}'][:, -predict_last_n:, :]\n",
    "    return y_hat_sub, y_sub\n",
    "\n",
    "\n",
    "def _evaluate(model, loader, l_obj, frequencies):\n",
    "    \"\"\"Evaluate model\"\"\"\n",
    "    predict_last_n = conf_obj.predict_last_n\n",
    "    # if isinstance(predict_last_n, int):\n",
    "    #     predict_last_n = {frequencies[0]: predict_last_n}  # if predict_last_n is int, there's only one frequency\n",
    "\n",
    "    preds, obs = {}, {}\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "\n",
    "            # for key in data:\n",
    "            #     data[key] = data[key].to(self.device)\n",
    "            predictions, loss = _get_predictions_and_loss(model, data, l_obj)\n",
    "\n",
    "            for freq in frequencies:\n",
    "                freq_key = f'_{freq}'\n",
    "                y_hat_sub, y_sub = _subset_targets(data, predictions, predict_last_n[freq], freq_key)\n",
    "\n",
    "                if freq not in preds:\n",
    "                    preds[freq] = y_hat_sub.detach().cpu()\n",
    "                    obs[freq] = y_sub.cpu()\n",
    "                else:\n",
    "                    preds[freq] = torch.cat((preds[freq], y_hat_sub.detach().cpu()), 0)\n",
    "                    obs[freq] = torch.cat((obs[freq], y_sub.detach().cpu()), 0)\n",
    "\n",
    "            losses.append(loss)\n",
    "\n",
    "        for freq in preds.keys():\n",
    "            preds[freq] = preds[freq].numpy()\n",
    "            obs[freq] = obs[freq].numpy()\n",
    "\n",
    "    # set to NaN explicitly if all losses are NaN to avoid RuntimeWarning\n",
    "    mean_loss = np.nanmean(losses) if len(losses) > 0 and not all(np.isnan(l) for l in losses) else np.nan\n",
    "    return preds, obs, mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression(nn.Module):\n",
    "    \n",
    "    \"\"\"Single-layer regression head with different output activations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_in : int\n",
    "        Number of input neurons.\n",
    "    n_out : int\n",
    "        Number of output neurons.\n",
    "    activation : str, optional\n",
    "        Output activation function. Can be specified in the config using the `output_activation` argument. Supported\n",
    "        are {'linear', 'relu', 'softplus'}. If not specified (or an unsupported activation function is specified), will\n",
    "        default to 'linear' activation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_in: int, n_out: int, activation: str = \"linear\"):\n",
    "        super(Regression, self).__init__()\n",
    "\n",
    "        # TODO: Add multi-layer support\n",
    "        layers = [nn.Linear(n_in, n_out)]\n",
    "        if activation != \"linear\":\n",
    "            if activation.lower() == \"relu\":\n",
    "                layers.append(nn.ReLU())\n",
    "            elif activation.lower() == \"softplus\":\n",
    "                layers.append(nn.Softplus())\n",
    "            else:\n",
    "                LOGGER.warning(f\"## WARNING: Ignored output activation {activation} and used 'linear' instead.\")\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Perform a forward pass on the Regression head.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, torch.Tensor]\n",
    "            Dictionary containing the model predictions in the 'y_hat' key.\n",
    "        \"\"\"\n",
    "        return {'y_hat': self.net(x)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_INPUT_DIM = 5\n",
    "HR_INPUT_DIM = 16\n",
    "INPUT_SIZE = {'1D': 5, '1H': 16}\n",
    "OUTPUT_DIM = 1\n",
    "HIDDEN_SIZE = {'1D': 20, '1H': 20}\n",
    "INITIAL_FORGET_BIAS = 3\n",
    "SHARED_MTSLSTM = False\n",
    "OUTPUT_DROPOUT = 0.4\n",
    "\n",
    "TRANSFER_MTSLSTM_STATES = {'h': 'linear', 'c': 'linear'}\n",
    "\n",
    "USE_FREQUENCIES = ['1D', '1H']\n",
    "OUTPUT_ACTIVATION = 'linear'\n",
    "\n",
    "DEVICE = 'cpu'\n",
    "\n",
    "SEQ_LENGTH = {'1D': 365, '1H': 336}\n",
    "PREDICT_LAST_N = {'1D': 1, '1H': 24}\n",
    "\n",
    "SLICE_TIMESTEP = {'1D': 14}\n",
    "FREUENCY_FACTORS = [24]\n",
    "\n",
    "#weights per target\n",
    "TARGET_WEIGHTS = [1.0]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AiBEDO_MTSLSTM(nn.Module):\n",
    "    \n",
    "    # specify submodules of the model that can later be used for finetuning. Names must match class attributes\n",
    "    module_parts = ['lstms', 'transfer_fcs', 'heads']\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AiBEDO_MTSLSTM, self).__init__()\n",
    "        self.output_size = OUTPUT_DIM\n",
    "        self.lstms = None\n",
    "        self.transfer_fcs = None\n",
    "        self.heads = None\n",
    "        self.dropout = None\n",
    "\n",
    "        self._slice_timestep = {}\n",
    "        self._frequency_factors = []\n",
    "\n",
    "        self._seq_lengths = SEQ_LENGTH\n",
    "        self._is_shared_mtslstm = SHARED_MTSLSTM  # default: a distinct LSTM per timescale\n",
    "        self._transfer_mtslstm_states = TRANSFER_MTSLSTM_STATES  # default: linear transfer layer\n",
    "        transfer_modes = [None, \"None\", \"identity\", \"linear\"]\n",
    "        if self._transfer_mtslstm_states[\"h\"] not in transfer_modes \\\n",
    "                or self._transfer_mtslstm_states[\"c\"] not in transfer_modes:\n",
    "            raise ValueError(f\"MTS-LSTM supports state transfer modes {transfer_modes}\")\n",
    "\n",
    "        # if len(cfg.use_frequencies) < 2:\n",
    "        #     raise ValueError(\"MTS-LSTM expects more than one input frequency\")\n",
    "        self._frequencies = USE_FREQUENCIES\n",
    "\n",
    "        # # start to count the number of inputs\n",
    "        # input_sizes = len(cfg.static_attributes + cfg.hydroatlas_attributes + cfg.evolving_attributes)\n",
    "\n",
    "        # # if is_shared_mtslstm, the LSTM gets an additional frequency flag as input.\n",
    "        # if self._is_shared_mtslstm:\n",
    "        #     input_sizes += len(self._frequencies)\n",
    "\n",
    "        # if cfg.use_basin_id_encoding:\n",
    "        #     input_sizes += cfg.number_of_basins\n",
    "        # if cfg.head.lower() == \"umal\":\n",
    "        #     input_sizes += 1\n",
    "\n",
    "        # if isinstance(cfg.dynamic_inputs, list):\n",
    "        #     input_sizes = {freq: input_sizes + len(cfg.dynamic_inputs) for freq in self._frequencies}\n",
    "        # else:\n",
    "        #     if self._is_shared_mtslstm:\n",
    "        #         raise ValueError(f'Different inputs not allowed if shared_mtslstm is used.')\n",
    "        #     input_sizes = {freq: input_sizes + len(cfg.dynamic_inputs[freq]) for freq in self._frequencies}\n",
    "        \n",
    "        \n",
    "        self._input_sizes = INPUT_SIZE\n",
    "        self._hidden_size = HIDDEN_SIZE\n",
    "\n",
    "        if (self._is_shared_mtslstm\n",
    "            or self._transfer_mtslstm_states[\"h\"] == \"identity\"\n",
    "            or self._transfer_mtslstm_states[\"c\"] == \"identity\") \\\n",
    "                and any(size != self._hidden_size[self._frequencies[0]] for size in self._hidden_size.values()):\n",
    "            raise ValueError(\"All hidden sizes must be equal if shared_mtslstm is used or state transfer=identity.\")\n",
    "\n",
    "        # create layer depending on selected frequencies\n",
    "        self._init_modules(self._input_sizes)\n",
    "        self._reset_parameters()\n",
    "\n",
    "        # frequency factors are needed to determine the time step of information transfer\n",
    "        #self._init_frequency_factors_and_slice_timesteps()\n",
    "        self._frequency_factors = FREUENCY_FACTORS\n",
    "        self._slice_timestep = SLICE_TIMESTEP\n",
    "\n",
    "    def _init_modules(self, input_sizes: Dict[str, int]):\n",
    "        self.lstms = nn.ModuleDict()\n",
    "        self.transfer_fcs = nn.ModuleDict()\n",
    "        self.heads = nn.ModuleDict()\n",
    "        self.dropout = nn.Dropout(p=OUTPUT_DROPOUT)\n",
    "        for idx, freq in enumerate(self._frequencies):\n",
    "            freq_input_size = input_sizes[freq]\n",
    "\n",
    "            if self._is_shared_mtslstm and idx > 0:\n",
    "                self.lstms[freq] = self.lstms[self._frequencies[idx - 1]]  # same LSTM for all frequencies.\n",
    "                self.heads[freq] = self.heads[self._frequencies[idx - 1]]  # same head for all frequencies.\n",
    "            else:\n",
    "                self.lstms[freq] = nn.LSTM(input_size=freq_input_size, hidden_size=self._hidden_size[freq])\n",
    "                #self.heads[freq] = get_head(self.cfg, n_in=self._hidden_size[freq], n_out=self.output_size)\n",
    "                self.heads[freq] = Regression(n_in=self._hidden_size[freq], n_out=self.output_size, activation=OUTPUT_ACTIVATION)\n",
    "                \n",
    "                \n",
    "\n",
    "            if idx < len(self._frequencies) - 1:\n",
    "                for state in [\"c\", \"h\"]:\n",
    "                    if self._transfer_mtslstm_states[state] == \"linear\":\n",
    "                        self.transfer_fcs[f\"{state}_{freq}\"] = nn.Linear(self._hidden_size[freq],\n",
    "                                                                         self._hidden_size[self._frequencies[idx + 1]])\n",
    "                    elif self._transfer_mtslstm_states[state] == \"identity\":\n",
    "                        self.transfer_fcs[f\"{state}_{freq}\"] = nn.Identity()\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "    # def _init_frequency_factors_and_slice_timesteps(self):\n",
    "    #     for idx, freq in enumerate(self._frequencies):\n",
    "    #         if idx < len(self._frequencies) - 1:\n",
    "    #             frequency_factor = get_frequency_factor(freq, self._frequencies[idx + 1])\n",
    "    #             if frequency_factor != int(frequency_factor):\n",
    "    #                 raise ValueError('Adjacent frequencies must be multiples of each other.')\n",
    "    #             self._frequency_factors.append(int(frequency_factor))\n",
    "    #             # we want to pass the state of the day _before_ the next higher frequency starts,\n",
    "    #             # because e.g. the mean of a day is stored at the same date at 00:00 in the morning.\n",
    "    #             slice_timestep = int(self._seq_lengths[self._frequencies[idx + 1]] / self._frequency_factors[idx])\n",
    "    #             self._slice_timestep[freq] = slice_timestep\n",
    "                \n",
    "    \n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        if INITIAL_FORGET_BIAS is not None:\n",
    "            for freq in self._frequencies:\n",
    "                hidden_size = self._hidden_size[freq]\n",
    "                self.lstms[freq].bias_hh_l0.data[hidden_size:2 * hidden_size] = INITIAL_FORGET_BIAS\n",
    "    \n",
    "    def _prepare_inputs(self, data: Dict[str, torch.Tensor], freq: str) -> torch.Tensor:\n",
    "        \"\"\"Concat all different inputs to the time series input\"\"\"\n",
    "        suffix = f\"_{freq}\"\n",
    "        # transpose to [seq_length, batch_size, n_features]\n",
    "        x_d = data[f'x_d{suffix}'].transpose(0, 1)\n",
    "\n",
    "        # concat all inputs\n",
    "        if f'x_s{suffix}' in data and 'x_one_hot' in data:\n",
    "            x_s = data[f'x_s{suffix}'].unsqueeze(0).repeat(x_d.shape[0], 1, 1)\n",
    "            x_one_hot = data['x_one_hot'].unsqueeze(0).repeat(x_d.shape[0], 1, 1)\n",
    "            x_d = torch.cat([x_d, x_s, x_one_hot], dim=-1)\n",
    "        elif f'x_s{suffix}' in data:\n",
    "            x_s = data[f'x_s{suffix}'].unsqueeze(0).repeat(x_d.shape[0], 1, 1)\n",
    "            x_d = torch.cat([x_d, x_s], dim=-1)\n",
    "        elif 'x_one_hot' in data:\n",
    "            x_one_hot = data['x_one_hot'].unsqueeze(0).repeat(x_d.shape[0], 1, 1)\n",
    "            x_d = torch.cat([x_d, x_one_hot], dim=-1)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if self._is_shared_mtslstm:\n",
    "            # add frequency one-hot encoding\n",
    "            idx = self._frequencies.index(freq)\n",
    "            one_hot_freq = torch.zeros(x_d.shape[0], x_d.shape[1], len(self._frequencies)).to(x_d)\n",
    "            one_hot_freq[:, :, idx] = 1\n",
    "            x_d = torch.cat([x_d, one_hot_freq], dim=2)\n",
    "\n",
    "        return x_d\n",
    "\n",
    "    def forward(self, data: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Perform a forward pass on the MTS-LSTM model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : Dict[str, torch.Tensor]\n",
    "            Input data for the forward pass. See the documentation overview of all models for details on the dict keys.\n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, torch.Tensor]\n",
    "            Model predictions for each target timescale.\n",
    "        \"\"\"\n",
    "        x_d = {freq: self._prepare_inputs(data, freq) for freq in self._frequencies}\n",
    "\n",
    "        # initial states for lowest frequencies are set to zeros\n",
    "        batch_size = x_d[self._frequencies[0]].shape[1]\n",
    "        lowest_freq_hidden_size = self._hidden_size[self._frequencies[0]]\n",
    "        h_0_transfer = x_d[self._frequencies[0]].new_zeros((1, batch_size, lowest_freq_hidden_size))\n",
    "        c_0_transfer = torch.zeros_like(h_0_transfer)\n",
    "\n",
    "        outputs = {}\n",
    "        for idx, freq in enumerate(self._frequencies):\n",
    "            if idx < len(self._frequencies) - 1:\n",
    "                # get predictions and state up to the time step of information transfer\n",
    "                slice_timestep = self._slice_timestep[freq]\n",
    "                lstm_output_slice1, (h_n_slice1, c_n_slice1) = self.lstms[freq](x_d[freq][:-slice_timestep],\n",
    "                                                                                (h_0_transfer, c_0_transfer))\n",
    "\n",
    "                # project the states through a hidden layer to the dimensions of the next LSTM\n",
    "                if self._transfer_mtslstm_states[\"h\"] is not None:\n",
    "                    h_0_transfer = self.transfer_fcs[f\"h_{freq}\"](h_n_slice1)\n",
    "                if self._transfer_mtslstm_states[\"c\"] is not None:\n",
    "                    c_0_transfer = self.transfer_fcs[f\"c_{freq}\"](c_n_slice1)\n",
    "\n",
    "                # get predictions of remaining part and concat results\n",
    "                lstm_output_slice2, _ = self.lstms[freq](x_d[freq][-slice_timestep:], (h_n_slice1, c_n_slice1))\n",
    "                lstm_output = torch.cat([lstm_output_slice1, lstm_output_slice2], dim=0)\n",
    "\n",
    "            else:\n",
    "                # for highest frequency, we can pass the entire sequence at once\n",
    "                lstm_output, _ = self.lstms[freq](x_d[freq], (h_0_transfer, c_0_transfer))\n",
    "\n",
    "            head_out = self.heads[freq](self.dropout(lstm_output.transpose(0, 1)))\n",
    "            outputs.update({f'{key}_{freq}': value for key, value in head_out.items()})\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOSS function class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from neuralhydrology.training.regularization import BaseRegularization\n",
    "from neuralhydrology.utils.config import Config\n",
    "\n",
    "ONE_OVER_2PI_SQUARED = 1.0 / np.sqrt(2.0 * np.pi)\n",
    "\n",
    "\n",
    "class BaseLoss_v1(torch.nn.Module):\n",
    "    \"\"\"Base loss class.\n",
    "\n",
    "    All losses extend this class by implementing `_get_loss`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cfg : Config\n",
    "        The run configuration.\n",
    "    prediction_keys : List[str]\n",
    "        List of keys that will be predicted. During the forward pass, the passed `prediction` dict\n",
    "        must contain these keys. Note that the keys listed here should be without frequency identifier.\n",
    "    ground_truth_keys : List[str]\n",
    "        List of ground truth keys that will be needed to compute the loss. During the forward pass, the\n",
    "        passed `data` dict must contain these keys. Note that the keys listed here should be without\n",
    "        frequency identifier.\n",
    "    additional_data : List[str], optional\n",
    "        Additional list of keys that will be taken from `data` in the forward pass to compute the loss.\n",
    "        For instance, this parameter can be used to pass the variances that are needed to compute an NSE.\n",
    "    output_size_per_target : int, optional\n",
    "        Number of model outputs (per element in `prediction_keys`) connected to a single target variable, by default 1. \n",
    "        For example for regression, one output (last dimension in `y_hat`) maps to one target variable. For mixture \n",
    "        models (e.g. GMM and CMAL) the number of outputs per target corresponds to the number of distributions \n",
    "        (`n_distributions`).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 prediction_keys: List[str],\n",
    "                 ground_truth_keys: List[str],\n",
    "                 additional_data: List[str] = None,\n",
    "                 output_size_per_target: int = 1):\n",
    "        super(BaseLoss_v1, self).__init__()\n",
    "        self._predict_last_n = PREDICT_LAST_N\n",
    "        self._frequencies = USE_FREQUENCIES\n",
    "        self._output_size_per_target = output_size_per_target\n",
    "\n",
    "        self._regularization_terms = []\n",
    "\n",
    "        # names of ground truth and prediction keys to be unpacked and subset to predict_last_n items.\n",
    "        self._prediction_keys = prediction_keys\n",
    "        self._ground_truth_keys = ground_truth_keys\n",
    "\n",
    "        # subclasses can use this list to register inputs to be unpacked during the forward call\n",
    "        # and passed as kwargs to _get_loss() without subsetting.\n",
    "        self._additional_data = []\n",
    "        if additional_data is not None:\n",
    "            self._additional_data = additional_data\n",
    "\n",
    "        # all classes allow per-target weights for multi-target settings. By default, all targets are weighted equally\n",
    "        if TARGET_WEIGHTS is None:\n",
    "            weights = torch.tensor([1 / OUTPUT_DIM for _ in range(OUTPUT_DIM)])\n",
    "        else:\n",
    "            if len(TARGET_WEIGHTS) == OUTPUT_DIM:\n",
    "                weights = torch.tensor(TARGET_WEIGHTS)\n",
    "            else:\n",
    "                raise ValueError(\"Number of weights must be equal to the number of target variables\")\n",
    "        self._target_weights = weights\n",
    "\n",
    "    def forward(self, prediction: Dict[str, torch.Tensor], data: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "        \"\"\"Calculate the loss.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        prediction : Dict[str, torch.Tensor]\n",
    "            Dictionary of predictions for each frequency. If more than one frequency is predicted,\n",
    "            the keys must have suffixes ``_{frequency}``. For the required keys, refer to the documentation\n",
    "            of the concrete loss.\n",
    "        data : Dict[str, torch.Tensor]\n",
    "            Dictionary of ground truth data for each frequency. If more than one frequency is predicted,\n",
    "            the keys must have suffixes ``_{frequency}``. For the required keys, refer to the documentation\n",
    "            of the concrete loss.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            The calculated loss.\n",
    "        \"\"\"\n",
    "        # unpack loss-specific additional arguments\n",
    "        kwargs = {key: data[key] for key in self._additional_data}\n",
    "\n",
    "        losses = []\n",
    "        prediction_sub, ground_truth_sub = {}, {}\n",
    "        for freq in self._frequencies:\n",
    "            if self._predict_last_n[freq] == 0:\n",
    "                continue  # no predictions for this frequency\n",
    "            freq_suffix = '' if freq == '' else f'_{freq}'\n",
    "\n",
    "            # apply predict_last_n and mask for all outputs of this frequency at once\n",
    "            freq_pred, freq_gt = self._subset_in_time(\n",
    "                {key: prediction[f'{key}{freq_suffix}'] for key in self._prediction_keys},\n",
    "                {key: data[f'{key}{freq_suffix}'] for key in self._ground_truth_keys}, self._predict_last_n[freq])\n",
    "\n",
    "            # remember subsets for multi-frequency component\n",
    "            prediction_sub.update({f'{key}{freq_suffix}': freq_pred[key] for key in freq_pred.keys()})\n",
    "            ground_truth_sub.update({f'{key}{freq_suffix}': freq_gt[key] for key in freq_gt.keys()})\n",
    "\n",
    "            for n_target, weight in enumerate(self._target_weights):\n",
    "                # subset the model outputs and ground truth corresponding to this particular target\n",
    "                target_pred, target_gt = self._subset_target(freq_pred, freq_gt, n_target)\n",
    "\n",
    "                # model hook to subset additional data, which might be different for different losses\n",
    "                kwargs_sub = self._subset_additional_data(kwargs, n_target)\n",
    "\n",
    "                loss = self._get_loss(target_pred, target_gt, **kwargs_sub)\n",
    "                losses.append(loss * weight)\n",
    "\n",
    "        loss = torch.sum(torch.stack(losses))\n",
    "        for regularization in self._regularization_terms:\n",
    "            loss = loss + regularization(prediction_sub, ground_truth_sub,\n",
    "                                         {k: v for k, v in prediction.items() if k not in self._prediction_keys})\n",
    "        return loss\n",
    "\n",
    "    @staticmethod\n",
    "    def _subset_in_time(prediction: Dict[str, torch.Tensor], ground_truth: Dict[str, torch.Tensor],\n",
    "                        predict_last_n: int) -> Tuple[Dict[str, torch.Tensor], Dict[str, torch.Tensor]]:\n",
    "        ground_truth_sub = {key: gt[:, -predict_last_n:, :] for key, gt in ground_truth.items()}\n",
    "        prediction_sub = {key: pred[:, -predict_last_n:, :] for key, pred in prediction.items()}\n",
    "\n",
    "        return prediction_sub, ground_truth_sub\n",
    "\n",
    "    def _subset_target(self, prediction: Dict[str, torch.Tensor], ground_truth: Dict[str, torch.Tensor],\n",
    "                       n_target: int) -> Tuple[Dict[str, torch.Tensor], Dict[str, torch.Tensor]]:\n",
    "        # determine which output neurons correspond to the n_target target variable\n",
    "        start = n_target * self._output_size_per_target\n",
    "        end = (n_target + 1) * self._output_size_per_target\n",
    "        prediction_sub = {key: pred[:, :, start:end] for key, pred in prediction.items()}\n",
    "\n",
    "        # subset target by slicing to keep shape [bs, seq, 1]\n",
    "        ground_truth_sub = {key: gt[:, :, n_target:n_target + 1] for key, gt in ground_truth.items()}\n",
    "\n",
    "        return prediction_sub, ground_truth_sub\n",
    "\n",
    "    @staticmethod\n",
    "    def _subset_additional_data(additional_data: Dict[str, torch.Tensor], n_target: int) -> Dict[str, torch.Tensor]:\n",
    "        # by default, nothing happens\n",
    "        return additional_data\n",
    "\n",
    "    def _get_loss(self, prediction: Dict[str, torch.Tensor], ground_truth: Dict[str, torch.Tensor], **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def set_regularization_terms(self, regularization_modules: List[BaseRegularization]):\n",
    "        \"\"\"Register the passed regularization terms to be added to the loss function.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        regularization_modules : List[BaseRegularization]\n",
    "            List of regularization functions to be added to the loss during `forward`.\n",
    "        \"\"\"\n",
    "        self._regularization_terms = regularization_modules\n",
    "\n",
    "\n",
    "class MaskedMSELoss_v1(BaseLoss_v1):\n",
    "    \"\"\"Mean squared error loss.\n",
    "\n",
    "    To use this loss in a forward pass, the passed `prediction` dict must contain\n",
    "    the key ``y_hat``, and the `data` dict must contain ``y``.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cfg : Config\n",
    "        The run configuration.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MaskedMSELoss_v1, self).__init__(prediction_keys=['y_hat'], ground_truth_keys=['y'])\n",
    "\n",
    "    def _get_loss(self, prediction: Dict[str, torch.Tensor], ground_truth: Dict[str, torch.Tensor], **kwargs):\n",
    "        mask = ~torch.isnan(ground_truth['y'])\n",
    "        loss = 0.5 * torch.mean((prediction['y_hat'][mask] - ground_truth['y'][mask])**2)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class MaskedRMSELoss_v1(BaseLoss_v1):\n",
    "    \"\"\"Root mean squared error loss.\n",
    "\n",
    "    To use this loss in a forward pass, the passed `prediction` dict must contain\n",
    "    the key ``y_hat``, and the `data` dict must contain ``y``.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cfg : Config\n",
    "        The run configuration.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MaskedRMSELoss_v1, self).__init__(prediction_keys=['y_hat'], ground_truth_keys=['y'])\n",
    "\n",
    "    def _get_loss(self, prediction: Dict[str, torch.Tensor], ground_truth: Dict[str, torch.Tensor], **kwargs):\n",
    "        mask = ~torch.isnan(ground_truth['y'])\n",
    "        loss = torch.sqrt(0.5 * torch.mean((prediction['y_hat'][mask] - ground_truth['y'][mask])**2))\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_predictions_and_loss(model, data, l_obj):\n",
    "    predictions = model(data)\n",
    "    loss = l_obj(predictions, data)\n",
    "    return predictions, loss.item()\n",
    "\n",
    "def _subset_targets(data, predictions, predict_last_n, freq):\n",
    "    y_hat_sub = predictions[f'y_hat{freq}'][:, -predict_last_n:, :]\n",
    "    y_sub = data[f'y{freq}'][:, -predict_last_n:, :]\n",
    "    return y_hat_sub, y_sub\n",
    "\n",
    "\n",
    "def _evaluate(model, loader, l_obj, frequencies):\n",
    "    \"\"\"Evaluate model\"\"\"\n",
    "    predict_last_n = PREDICT_LAST_N\n",
    "    # if isinstance(predict_last_n, int):\n",
    "    #     predict_last_n = {frequencies[0]: predict_last_n}  # if predict_last_n is int, there's only one frequency\n",
    "\n",
    "    preds, obs = {}, {}\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "\n",
    "            # for key in data:\n",
    "            #     data[key] = data[key].to(self.device)\n",
    "            predictions, loss = _get_predictions_and_loss(model, data, l_obj)\n",
    "\n",
    "            for freq in frequencies:\n",
    "                freq_key = f'_{freq}'\n",
    "                y_hat_sub, y_sub = _subset_targets(data, predictions, predict_last_n[freq], freq_key)\n",
    "\n",
    "                if freq not in preds:\n",
    "                    preds[freq] = y_hat_sub.detach().cpu()\n",
    "                    obs[freq] = y_sub.cpu()\n",
    "                else:\n",
    "                    preds[freq] = torch.cat((preds[freq], y_hat_sub.detach().cpu()), 0)\n",
    "                    obs[freq] = torch.cat((obs[freq], y_sub.detach().cpu()), 0)\n",
    "\n",
    "            losses.append(loss)\n",
    "\n",
    "        for freq in preds.keys():\n",
    "            preds[freq] = preds[freq].numpy()\n",
    "            obs[freq] = obs[freq].numpy()\n",
    "\n",
    "    # set to NaN explicitly if all losses are NaN to avoid RuntimeWarning\n",
    "    mean_loss = np.nanmean(losses) if len(losses) > 0 and not all(np.isnan(l) for l in losses) else np.nan\n",
    "    return preds, obs, mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = AiBEDO_MTSLSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1D': 5, '1H': 16}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model._input_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AiBEDO_MTSLSTM(\n",
       "  (lstms): ModuleDict(\n",
       "    (1D): LSTM(5, 20)\n",
       "    (1H): LSTM(16, 20)\n",
       "  )\n",
       "  (transfer_fcs): ModuleDict(\n",
       "    (c_1D): Linear(in_features=20, out_features=20, bias=True)\n",
       "    (h_1D): Linear(in_features=20, out_features=20, bias=True)\n",
       "  )\n",
       "  (heads): ModuleDict(\n",
       "    (1D): Regression(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=20, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (1H): Regression(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=20, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(new_model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_obj = MaskedMSELoss_v1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11/11 [00:03<00:00,  2.82it/s, Loss: 0.3788]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. validation loss 0.35441458225250244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11/11 [00:03<00:00,  2.82it/s, Loss: 0.4825]\n",
      "100%|| 11/11 [00:03<00:00,  2.83it/s, Loss: 0.2432]\n",
      "100%|| 11/11 [00:03<00:00,  2.82it/s, Loss: 0.5124]\n",
      "100%|| 11/11 [00:03<00:00,  2.80it/s, Loss: 0.5175]\n",
      "100%|| 11/11 [00:03<00:00,  2.81it/s, Loss: 0.3289]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. validation loss 0.24830869138240813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11/11 [00:03<00:00,  2.81it/s, Loss: 0.2000]\n",
      "100%|| 11/11 [00:03<00:00,  2.80it/s, Loss: 0.1545]\n",
      "100%|| 11/11 [00:04<00:00,  2.75it/s, Loss: 0.1832]\n",
      "100%|| 11/11 [00:03<00:00,  2.78it/s, Loss: 0.1938]\n",
      "100%|| 11/11 [00:04<00:00,  2.67it/s, Loss: 0.2100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. validation loss 0.3047953963279724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11/11 [00:03<00:00,  2.81it/s, Loss: 0.1944]\n",
      "100%|| 11/11 [00:03<00:00,  2.79it/s, Loss: 0.2103]\n",
      "100%|| 11/11 [00:03<00:00,  2.80it/s, Loss: 0.1588]\n",
      "100%|| 11/11 [00:04<00:00,  2.73it/s, Loss: 0.1779]\n",
      "100%|| 11/11 [00:03<00:00,  2.81it/s, Loss: 0.1538]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. validation loss 0.24029682576656342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11/11 [00:03<00:00,  2.79it/s, Loss: 0.1981]\n",
      "100%|| 11/11 [00:03<00:00,  2.83it/s, Loss: 0.1700]\n",
      "100%|| 11/11 [00:03<00:00,  2.80it/s, Loss: 0.1637]\n",
      "100%|| 11/11 [00:03<00:00,  2.81it/s, Loss: 0.1200]\n",
      "100%|| 11/11 [00:03<00:00,  2.79it/s, Loss: 0.1036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. validation loss 0.2982554376125336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11/11 [00:03<00:00,  2.79it/s, Loss: 0.1199]\n",
      "100%|| 11/11 [00:03<00:00,  2.80it/s, Loss: 0.0862]\n",
      "100%|| 11/11 [00:03<00:00,  2.80it/s, Loss: 0.1550]\n",
      "100%|| 11/11 [00:03<00:00,  2.80it/s, Loss: 0.1364]\n",
      "100%|| 11/11 [00:03<00:00,  2.79it/s, Loss: 0.1055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. validation loss 0.20522066354751586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11/11 [00:03<00:00,  2.80it/s, Loss: 0.1183]\n",
      "100%|| 11/11 [00:03<00:00,  2.80it/s, Loss: 0.1294]\n",
      "100%|| 11/11 [00:03<00:00,  2.81it/s, Loss: 0.0862]\n",
      "100%|| 11/11 [00:03<00:00,  2.80it/s, Loss: 0.1403]\n",
      "100%|| 11/11 [00:03<00:00,  2.81it/s, Loss: 0.0953]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. validation loss 0.23465182185173034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11/11 [00:03<00:00,  2.78it/s, Loss: 0.0983]\n",
      "100%|| 11/11 [00:03<00:00,  2.79it/s, Loss: 0.1243]\n",
      "100%|| 11/11 [00:03<00:00,  2.82it/s, Loss: 0.1057]\n",
      "100%|| 11/11 [00:03<00:00,  2.81it/s, Loss: 0.0876]\n",
      "100%|| 11/11 [00:03<00:00,  2.78it/s, Loss: 0.1156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. validation loss 0.2140289753675461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11/11 [00:03<00:00,  2.78it/s, Loss: 0.0881]\n",
      "100%|| 11/11 [00:03<00:00,  2.81it/s, Loss: 0.1339]\n",
      "100%|| 11/11 [00:03<00:00,  2.82it/s, Loss: 0.1217]\n",
      "100%|| 11/11 [00:03<00:00,  2.80it/s, Loss: 0.1209]\n",
      "100%|| 11/11 [00:03<00:00,  2.79it/s, Loss: 0.1002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. validation loss 0.21514617800712585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11/11 [00:03<00:00,  2.78it/s, Loss: 0.1110]\n",
      "100%|| 11/11 [00:03<00:00,  2.78it/s, Loss: 0.0993]\n",
      "100%|| 11/11 [00:03<00:00,  2.81it/s, Loss: 0.0868]\n",
      "100%|| 11/11 [00:03<00:00,  2.80it/s, Loss: 0.0869]\n",
      "100%|| 11/11 [00:03<00:00,  2.79it/s, Loss: 0.1109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. validation loss 0.23508144915103912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 11/11 [00:03<00:00,  2.81it/s, Loss: 0.0934]\n",
      "100%|| 11/11 [00:03<00:00,  2.78it/s, Loss: 0.0685]\n",
      "100%|| 11/11 [00:03<00:00,  2.78it/s, Loss: 0.1048]\n",
      "100%|| 11/11 [00:03<00:00,  2.79it/s, Loss: 0.0715]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    new_model.train()\n",
    "    pbar = tqdm(dl_train)\n",
    "    \n",
    "    for data in pbar:\n",
    "        predictions = new_model(data)\n",
    "        loss_val = loss_obj(predictions, data)\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(new_model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        \n",
    "        pbar.set_postfix_str(f\"Loss: {loss_val.item():.4f}\")\n",
    "    \n",
    "    if epoch%5 == 0:    \n",
    "        ## validate\n",
    "        new_model.eval()\n",
    "        _, _, avg_val_loss = _evaluate(new_model, dl_val, loss_obj, USE_FREQUENCIES)\n",
    "        print(\"Avg. validation loss\", avg_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ruamel.yaml import YAML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "yml_path = Path('aibedo.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "if yml_path.exists():\n",
    "    with yml_path.open('r') as fp:\n",
    "        yaml = YAML(typ=\"safe\")\n",
    "        cfg_test = yaml.load(fp)\n",
    "else:\n",
    "    raise FileNotFoundError(yml_path)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowres_input_dimension 5\n",
      "highres_input_dimension 16\n",
      "output_dim 1\n",
      "shared_mtslstm False\n",
      "transfer_mtslstm_states {'h': 'linear', 'c': 'linear'}\n",
      "output_activation linear\n",
      "hidden_size 20\n",
      "initial_forget_bias 3\n",
      "output_dropout 0.4\n",
      "device cpu\n",
      "optimizer Adam\n",
      "loss MSE\n",
      "regularization ['tie_frequencies']\n",
      "batch_size 256\n",
      "epochs 50\n",
      "clip_gradient_norm 1\n",
      "predict_last_n {'1D': 1, '1H': 24}\n",
      "seq_length {'1D': 365, '1H': 336}\n",
      "num_workers 8\n",
      "log_interval 5\n",
      "log_tensorboard False\n",
      "log_n_figures 0\n",
      "save_weights_every 1\n"
     ]
    }
   ],
   "source": [
    "for k in cfg_test.keys():\n",
    "    print(k, cfg_test[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_INPUT_DIM = 5\n",
    "HR_INPUT_DIM = 16\n",
    "INPUT_SIZE = {'1D': 5, '1H': 16}\n",
    "OUTPUT_DIM = 1\n",
    "HIDDEN_SIZE = {'1D': 20, '1H': 20}\n",
    "INITIAL_FORGET_BIAS = 3\n",
    "SHARED_MTSLSTM = False\n",
    "OUTPUT_DROPOUT = 0.4\n",
    "\n",
    "TRANSFER_MTSLSTM_STATES = {'h': 'linear', 'c': 'linear'}\n",
    "\n",
    "USE_FREQUENCIES = ['1D', '1H']\n",
    "OUTPUT_ACTIVATION = 'linear'\n",
    "\n",
    "DEVICE = 'cpu'\n",
    "\n",
    "SEQ_LENGTH = {'1D': 365, '1H': 336}\n",
    "PREDICT_LAST_N = {'1D': 1, '1H': 24}\n",
    "\n",
    "SLICE_TIMESTEP = {'1D': 14}\n",
    "FREUENCY_FACTORS = [24]\n",
    "\n",
    "#weights per target\n",
    "TARGET_WEIGHTS = [1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AiBEDOConfig():\n",
    "    def __init__(self, yml_path: Path):\n",
    "        \n",
    "        if yml_path.exists():\n",
    "            with yml_path.open('r') as fp:\n",
    "                yaml = YAML(typ=\"safe\")\n",
    "                _cfg_dict = yaml.load(fp)\n",
    "        else:\n",
    "            raise FileNotFoundError(yml_path)\n",
    "        \n",
    "        self.num_variables = len(_cfg_dict)\n",
    "        self.input_size = _cfg_dict['input_size']\n",
    "        self.output_dim = _cfg_dict['output_dim']\n",
    "        self.hidden_size = _cfg_dict['hidden_size']\n",
    "        \n",
    "        self.initial_forget_bias = _cfg_dict['initial_forget_bias']\n",
    "        self.shared_mtslstm = _cfg_dict['shared_mtslstm']\n",
    "        self.output_dropout = _cfg_dict['output_dropout']\n",
    "        \n",
    "        self.transfer_mtslstm_states = _cfg_dict['transfer_mtslstm_states']\n",
    "        self.use_frequencies = _cfg_dict['use_frequencies']\n",
    "        self.output_activation = _cfg_dict['output_activation']\n",
    "        \n",
    "        self.device = _cfg_dict['device']\n",
    "        \n",
    "        self.seq_length = _cfg_dict['seq_length']\n",
    "        self.predict_last_n = _cfg_dict['predict_last_n']\n",
    "        self.slice_timestep = _cfg_dict['slice_timestep']\n",
    "        self.frequency_factors = _cfg_dict['frequency_factors']\n",
    "        \n",
    "        self.target_weights = _cfg_dict['target_weights']\n",
    "\n",
    "        \n",
    "         \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_v1 = AiBEDOConfig(Path('aibedo.yml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_v1.frequency_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cfg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_conf = Config(Path('example.yml'), dev_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Config' object has no attribute 'a_dictionary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d7/b67pt0n53v9f8nx6qbgw42pdmxcryv/T/ipykernel_46295/429909483.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_conf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma_dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Config' object has no attribute 'a_dictionary'"
     ]
    }
   ],
   "source": [
    "test_conf.a_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7899590b5c0f438fccbc783835e621039bdcffae55ac391b3f28e538fb49d501"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('aibedo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
