{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refactoring MTS-LSTM model\n",
    "* understand the dependency of the mts-lstm model in neurohydrology\n",
    "* develop a skeleton model for Aibedo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Optional, Callable\n",
    "import logging\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from neuralhydrology.utils.config import Config\n",
    "from neuralhydrology.utils.samplingutils import sample_pointpredictions\n",
    "from neuralhydrology.datautils.utils import get_frequency_factor, sort_frequencies\n",
    "from neuralhydrology.modelzoo.head import get_head\n",
    "\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refactored Abstract class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    \n",
    "    # specify submodules of the model that can later be used for finetuning. Names must match class attributes\n",
    "    module_parts = []\n",
    "\n",
    "    def __init__(self, cfg: Config):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.cfg = cfg\n",
    "        self.output_size = len(cfg.target_variables)\n",
    "        # if cfg.head.lower() == 'gmm':\n",
    "        #     self.output_size *= 3 * cfg.n_distributions\n",
    "        # elif cfg.head.lower() == 'cmal':\n",
    "        #     self.output_size *= 4 * cfg.n_distributions\n",
    "        # elif cfg.head.lower() == 'umal':\n",
    "        #     self.output_size *= 2\n",
    "\n",
    "    def sample(self, data: Dict[str, torch.Tensor], n_samples: int) -> Dict[str, torch.Tensor]:\n",
    "        \n",
    "        return sample_pointpredictions(self, data, n_samples)\n",
    "\n",
    "    def forward(self, data: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        \n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTSLSTM(BaseModel):\n",
    "    \n",
    "    # specify submodules of the model that can later be used for finetuning. Names must match class attributes\n",
    "    module_parts = ['lstms', 'transfer_fcs', 'heads']\n",
    "\n",
    "    def __init__(self, cfg: Config):\n",
    "        super(MTSLSTM, self).__init__(cfg=cfg)\n",
    "        self.lstms = None\n",
    "        self.transfer_fcs = None\n",
    "        self.heads = None\n",
    "        self.dropout = None\n",
    "\n",
    "        self._slice_timestep = {}\n",
    "        self._frequency_factors = []\n",
    "\n",
    "        self._seq_lengths = cfg.seq_length\n",
    "        self._is_shared_mtslstm = self.cfg.shared_mtslstm  # default: a distinct LSTM per timescale\n",
    "        self._transfer_mtslstm_states = self.cfg.transfer_mtslstm_states  # default: linear transfer layer\n",
    "        transfer_modes = [None, \"None\", \"identity\", \"linear\"]\n",
    "        if self._transfer_mtslstm_states[\"h\"] not in transfer_modes \\\n",
    "                or self._transfer_mtslstm_states[\"c\"] not in transfer_modes:\n",
    "            raise ValueError(f\"MTS-LSTM supports state transfer modes {transfer_modes}\")\n",
    "\n",
    "        if len(cfg.use_frequencies) < 2:\n",
    "            raise ValueError(\"MTS-LSTM expects more than one input frequency\")\n",
    "        self._frequencies = sort_frequencies(cfg.use_frequencies)\n",
    "\n",
    "        # start to count the number of inputs\n",
    "        input_sizes = len(cfg.static_attributes + cfg.hydroatlas_attributes + cfg.evolving_attributes)\n",
    "\n",
    "        # if is_shared_mtslstm, the LSTM gets an additional frequency flag as input.\n",
    "        if self._is_shared_mtslstm:\n",
    "            input_sizes += len(self._frequencies)\n",
    "\n",
    "        if cfg.use_basin_id_encoding:\n",
    "            input_sizes += cfg.number_of_basins\n",
    "        if cfg.head.lower() == \"umal\":\n",
    "            input_sizes += 1\n",
    "\n",
    "        if isinstance(cfg.dynamic_inputs, list):\n",
    "            input_sizes = {freq: input_sizes + len(cfg.dynamic_inputs) for freq in self._frequencies}\n",
    "        else:\n",
    "            if self._is_shared_mtslstm:\n",
    "                raise ValueError(f'Different inputs not allowed if shared_mtslstm is used.')\n",
    "            input_sizes = {freq: input_sizes + len(cfg.dynamic_inputs[freq]) for freq in self._frequencies}\n",
    "\n",
    "        if not isinstance(cfg.hidden_size, dict):\n",
    "            LOGGER.info(\"No specific hidden size for frequencies are specified. Same hidden size is used for all.\")\n",
    "            self._hidden_size = {freq: cfg.hidden_size for freq in self._frequencies}\n",
    "        else:\n",
    "            self._hidden_size = cfg.hidden_size\n",
    "\n",
    "        if (self._is_shared_mtslstm\n",
    "            or self._transfer_mtslstm_states[\"h\"] == \"identity\"\n",
    "            or self._transfer_mtslstm_states[\"c\"] == \"identity\") \\\n",
    "                and any(size != self._hidden_size[self._frequencies[0]] for size in self._hidden_size.values()):\n",
    "            raise ValueError(\"All hidden sizes must be equal if shared_mtslstm is used or state transfer=identity.\")\n",
    "\n",
    "        # create layer depending on selected frequencies\n",
    "        self._init_modules(input_sizes)\n",
    "        self._reset_parameters()\n",
    "\n",
    "        # frequency factors are needed to determine the time step of information transfer\n",
    "        self._init_frequency_factors_and_slice_timesteps()\n",
    "\n",
    "    def _init_modules(self, input_sizes: Dict[str, int]):\n",
    "        self.lstms = nn.ModuleDict()\n",
    "        self.transfer_fcs = nn.ModuleDict()\n",
    "        self.heads = nn.ModuleDict()\n",
    "        self.dropout = nn.Dropout(p=self.cfg.output_dropout)\n",
    "        for idx, freq in enumerate(self._frequencies):\n",
    "            freq_input_size = input_sizes[freq]\n",
    "\n",
    "            if self._is_shared_mtslstm and idx > 0:\n",
    "                self.lstms[freq] = self.lstms[self._frequencies[idx - 1]]  # same LSTM for all frequencies.\n",
    "                self.heads[freq] = self.heads[self._frequencies[idx - 1]]  # same head for all frequencies.\n",
    "            else:\n",
    "                self.lstms[freq] = nn.LSTM(input_size=freq_input_size, hidden_size=self._hidden_size[freq])\n",
    "                self.heads[freq] = get_head(self.cfg, n_in=self._hidden_size[freq], n_out=self.output_size)\n",
    "\n",
    "            if idx < len(self._frequencies) - 1:\n",
    "                for state in [\"c\", \"h\"]:\n",
    "                    if self._transfer_mtslstm_states[state] == \"linear\":\n",
    "                        self.transfer_fcs[f\"{state}_{freq}\"] = nn.Linear(self._hidden_size[freq],\n",
    "                                                                         self._hidden_size[self._frequencies[idx + 1]])\n",
    "                    elif self._transfer_mtslstm_states[state] == \"identity\":\n",
    "                        self.transfer_fcs[f\"{state}_{freq}\"] = nn.Identity()\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "    def _init_frequency_factors_and_slice_timesteps(self):\n",
    "        for idx, freq in enumerate(self._frequencies):\n",
    "            if idx < len(self._frequencies) - 1:\n",
    "                frequency_factor = get_frequency_factor(freq, self._frequencies[idx + 1])\n",
    "                if frequency_factor != int(frequency_factor):\n",
    "                    raise ValueError('Adjacent frequencies must be multiples of each other.')\n",
    "                self._frequency_factors.append(int(frequency_factor))\n",
    "                # we want to pass the state of the day _before_ the next higher frequency starts,\n",
    "                # because e.g. the mean of a day is stored at the same date at 00:00 in the morning.\n",
    "                slice_timestep = int(self._seq_lengths[self._frequencies[idx + 1]] / self._frequency_factors[idx])\n",
    "                self._slice_timestep[freq] = slice_timestep\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        if self.cfg.initial_forget_bias is not None:\n",
    "            for freq in self._frequencies:\n",
    "                hidden_size = self._hidden_size[freq]\n",
    "                self.lstms[freq].bias_hh_l0.data[hidden_size:2 * hidden_size] = self.cfg.initial_forget_bias\n",
    "\n",
    "    def _prepare_inputs(self, data: Dict[str, torch.Tensor], freq: str) -> torch.Tensor:\n",
    "        \"\"\"Concat all different inputs to the time series input\"\"\"\n",
    "        suffix = f\"_{freq}\"\n",
    "        # transpose to [seq_length, batch_size, n_features]\n",
    "        x_d = data[f'x_d{suffix}'].transpose(0, 1)\n",
    "\n",
    "        # concat all inputs\n",
    "        if f'x_s{suffix}' in data and 'x_one_hot' in data:\n",
    "            x_s = data[f'x_s{suffix}'].unsqueeze(0).repeat(x_d.shape[0], 1, 1)\n",
    "            x_one_hot = data['x_one_hot'].unsqueeze(0).repeat(x_d.shape[0], 1, 1)\n",
    "            x_d = torch.cat([x_d, x_s, x_one_hot], dim=-1)\n",
    "        elif f'x_s{suffix}' in data:\n",
    "            x_s = data[f'x_s{suffix}'].unsqueeze(0).repeat(x_d.shape[0], 1, 1)\n",
    "            x_d = torch.cat([x_d, x_s], dim=-1)\n",
    "        elif 'x_one_hot' in data:\n",
    "            x_one_hot = data['x_one_hot'].unsqueeze(0).repeat(x_d.shape[0], 1, 1)\n",
    "            x_d = torch.cat([x_d, x_one_hot], dim=-1)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if self._is_shared_mtslstm:\n",
    "            # add frequency one-hot encoding\n",
    "            idx = self._frequencies.index(freq)\n",
    "            one_hot_freq = torch.zeros(x_d.shape[0], x_d.shape[1], len(self._frequencies)).to(x_d)\n",
    "            one_hot_freq[:, :, idx] = 1\n",
    "            x_d = torch.cat([x_d, one_hot_freq], dim=2)\n",
    "\n",
    "        return x_d\n",
    "\n",
    "    def forward(self, data: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Perform a forward pass on the MTS-LSTM model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        data : Dict[str, torch.Tensor]\n",
    "            Input data for the forward pass. See the documentation overview of all models for details on the dict keys.\n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, torch.Tensor]\n",
    "            Model predictions for each target timescale.\n",
    "        \"\"\"\n",
    "        x_d = {freq: self._prepare_inputs(data, freq) for freq in self._frequencies}\n",
    "\n",
    "        # initial states for lowest frequencies are set to zeros\n",
    "        batch_size = x_d[self._frequencies[0]].shape[1]\n",
    "        lowest_freq_hidden_size = self._hidden_size[self._frequencies[0]]\n",
    "        h_0_transfer = x_d[self._frequencies[0]].new_zeros((1, batch_size, lowest_freq_hidden_size))\n",
    "        c_0_transfer = torch.zeros_like(h_0_transfer)\n",
    "\n",
    "        outputs = {}\n",
    "        for idx, freq in enumerate(self._frequencies):\n",
    "            if idx < len(self._frequencies) - 1:\n",
    "                # get predictions and state up to the time step of information transfer\n",
    "                slice_timestep = self._slice_timestep[freq]\n",
    "                lstm_output_slice1, (h_n_slice1, c_n_slice1) = self.lstms[freq](x_d[freq][:-slice_timestep],\n",
    "                                                                                (h_0_transfer, c_0_transfer))\n",
    "\n",
    "                # project the states through a hidden layer to the dimensions of the next LSTM\n",
    "                if self._transfer_mtslstm_states[\"h\"] is not None:\n",
    "                    h_0_transfer = self.transfer_fcs[f\"h_{freq}\"](h_n_slice1)\n",
    "                if self._transfer_mtslstm_states[\"c\"] is not None:\n",
    "                    c_0_transfer = self.transfer_fcs[f\"c_{freq}\"](c_n_slice1)\n",
    "\n",
    "                # get predictions of remaining part and concat results\n",
    "                lstm_output_slice2, _ = self.lstms[freq](x_d[freq][-slice_timestep:], (h_n_slice1, c_n_slice1))\n",
    "                lstm_output = torch.cat([lstm_output_slice1, lstm_output_slice2], dim=0)\n",
    "\n",
    "            else:\n",
    "                # for highest frequency, we can pass the entire sequence at once\n",
    "                lstm_output, _ = self.lstms[freq](x_d[freq], (h_0_transfer, c_0_transfer))\n",
    "\n",
    "            head_out = self.heads[freq](self.dropout(lstm_output.transpose(0, 1)))\n",
    "            outputs.update({f'{key}_{freq}': value for key, value in head_out.items()})\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the configuration file as par neuralhydrology format\n",
    "* need to understand which features will be helpful Aibedo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_obj = Config(Path('mytest_basin.yml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'REGRESSION'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_obj.head.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = MTSLSTM(conf_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MTSLSTM(\n",
       "  (lstms): ModuleDict(\n",
       "    (1D): LSTM(5, 20)\n",
       "    (1H): LSTM(16, 20)\n",
       "  )\n",
       "  (transfer_fcs): ModuleDict(\n",
       "    (c_1D): Linear(in_features=20, out_features=20, bias=True)\n",
       "    (h_1D): Linear(in_features=20, out_features=20, bias=True)\n",
       "  )\n",
       "  (heads): ModuleDict(\n",
       "    (1D): Regression(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=20, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (1H): Regression(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=20, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dropout(p=0.4, inplace=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "64bcadabe4cd61f3d117ba0da9d14bf2f8e35582ff79e821f2e71056f2723d1e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('py38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
